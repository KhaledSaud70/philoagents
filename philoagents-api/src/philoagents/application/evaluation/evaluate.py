import asyncio

import opik
from loguru import logger
from opik.evaluation import evaluate
from opik.evaluation.metrics import (
    AnswerRelevance,
    ContextPrecision,
    ContextRecall,
    Hallucination,
    Moderation,
)

from philoagents.application.conversation_service.generate_response import get_response
from philoagents.application.conversation_service.workflow import state_to_str
from philoagents.config import settings
from philoagents.domain.philosopher_factory import PhilosopherFactory


async def evaluation_task(x: dict) -> dict:
    """
    Asynchronously evaluates philosopher responses using the agentic app logic.

    Args:
        x (dict): Evaluation data containing:
            - messages (list): Conversation messages, where all but the last are inputs,
              and the last is the expected output.
            - philosopher_id (str): Identifier of the philosopher to use.

    Returns:
        dict: Evaluation results containing:
            - input (list): Original input messages.
            - context (any): Context used for generating the response.
            - output (str): Response generated by the philosopher.
            - expected_output (str): Expected answer for comparison.
    """

    philosopher_factory = PhilosopherFactory()
    philosopher = philosopher_factory.get_philosopher(x["philosopher_id"])

    input_messages = x["messages"][:-1]
    expected_output_message = x["messages"][-1]

    response, latest_state = await get_response(
        messages=input_messages,
        philosopher_id=philosopher.id,
        philosopher_name=philosopher.name,
        philosopher_perspective=philosopher.perspective,
        philosopher_style=philosopher.style,
        philosopher_context="",
        new_thread=True,
    )
    context = state_to_str(latest_state)

    return {
        "input": input_messages,
        "context": context,
        "output": response,
        "expected_output": expected_output_message,
    }


def get_used_prompts() -> list[opik.Prompt]:
    client = opik.Opik()

    prompts = [
        client.get_prompt(name="philosopher_character_card"),
        client.get_prompt(name="summary_prompt"),
        client.get_prompt(name="extend_summary_prompt"),
    ]
    prompts = [p for p in prompts if p is not None]

    return prompts


def evaluate_agent(
    dataset: opik.Dataset | None, workers: int = 2, nb_samples: int | None = None
) -> None:
    """
    Evaluate an agent on a dataset using the Opik framework and configured metrics.

    Runs evaluation with metrics for hallucination, answer relevance, moderation,
    and context recall.

    Args:
        dataset (opik.Dataset | None): Dataset containing evaluation examples.
            Each example must include `messages` and `philosopher_id`.
        workers (int): Number of parallel workers to use for evaluation. Defaults to 2.
        nb_samples (int | None): Number of samples to evaluate. If None, evaluates
            the entire dataset.

    Raises:
        ValueError: If `dataset` is None.
        AssertionError: If `COMET_API_KEY` is not set.
    """

    assert settings.COMET_API_KEY, (
        "COMET_API_KEY is not set. It is required to trach the experiment with Opik."
    )

    if not dataset:
        raise ValueError("Dataset is 'None'.")

    logger.info("Starting evaluation ...")

    experiment_config = {
        "model_id": settings.GROQ_LLM_MODEL,
        "dataset_name": dataset.name,
    }
    used_prompts = get_used_prompts()

    scoring_metrics = [
        Hallucination(),
        AnswerRelevance(),
        Moderation(),
        ContextRecall(),
        ContextPrecision(),
    ]

    logger.info("Evaluation details")
    logger.info(f"Dataset: {dataset.name}")
    logger.info(f"Metrics: {[m.__class__.__name__ for m in scoring_metrics]}")

    evaluate(
        dataset=dataset,
        task=lambda x: asyncio.run(evaluation_task(x)),
        scoring_metrics=scoring_metrics,
        experiment_config=experiment_config,
        task_threads=workers,
        nb_samples=nb_samples,
        prompts=used_prompts,
    )
